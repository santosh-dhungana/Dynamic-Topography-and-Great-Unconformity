{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40395d25-c5ed-45a1-9ac8-6410836d505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "# ---------------------------\n",
    "# üß© GLOBAL PATH REGEX\n",
    "# ---------------------------\n",
    "\n",
    "# Compile regex once globally\n",
    "PATH_PATTERN = re.compile(\n",
    "    r\"\"\"([fF]?[\"'])           # optional f/F for f-string, opening quote\n",
    "        (                       # capture group\n",
    "            (?:                 # non-capturing group for path content\n",
    "                [^\"'\\\\]+       # any char except quotes\n",
    "                |\\\\[\"']        # allow escaped quotes\n",
    "            )+\n",
    "        )\n",
    "    \\1\"\"\",\n",
    "    re.VERBOSE\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# üß© PATH EXTRACTION\n",
    "# ---------------------------\n",
    "\n",
    "def extract_paths_from_code(source):\n",
    "    \"\"\"Extract only strings that look like file paths\"\"\"\n",
    "    if '/' not in source and '*' not in source:\n",
    "        return []\n",
    "\n",
    "    matches = PATH_PATTERN.findall(source)\n",
    "    paths = set()\n",
    "    for match in matches:\n",
    "        candidate = match[1]\n",
    "        if '/' in candidate or '\\\\' in candidate or '*' in candidate:\n",
    "            norm_path = os.path.normpath(candidate)\n",
    "            paths.add(norm_path)\n",
    "    return sorted(paths)\n",
    "\n",
    "\n",
    "def extract_paths_from_notebook(nb_path):\n",
    "    \"\"\"Extract paths from a notebook file.\"\"\"\n",
    "    try:\n",
    "        with open(nb_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            notebook = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {nb_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    paths = set()\n",
    "    for cell in notebook.get(\"cells\", []):\n",
    "        if cell.get(\"cell_type\") == \"code\":\n",
    "            source = \"\".join(cell.get(\"source\", []))\n",
    "            paths.update(extract_paths_from_code(source))\n",
    "\n",
    "    return sorted(paths)\n",
    "\n",
    "\n",
    "def extract_description_from_notebook(nb_path):\n",
    "    \"\"\"Return first markdown cell or top docstring as short description.\"\"\"\n",
    "    try:\n",
    "        with open(nb_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            notebook = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {nb_path}: {e}\")\n",
    "        return \"No description available.\"\n",
    "\n",
    "    for cell in notebook.get(\"cells\", []):\n",
    "        if cell.get(\"cell_type\") == \"markdown\":\n",
    "            text = \"\".join(cell.get(\"source\", [])).strip()\n",
    "            if text:\n",
    "                return text.split(\"\\n\")[0][:300]\n",
    "        if cell.get(\"cell_type\") == \"code\":\n",
    "            src = \"\".join(cell.get(\"source\", []))\n",
    "            doc_match = re.match(r'\"\"\"(.*?)\"\"\"', src, re.DOTALL)\n",
    "            if doc_match:\n",
    "                return doc_match.group(1).split(\"\\n\")[0][:300]\n",
    "\n",
    "    return \"No description available.\"\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# üå≥ PATH TREE\n",
    "# ---------------------------\n",
    "\n",
    "def build_path_tree(paths):\n",
    "    \"\"\"Convert list of paths into nested dict structure.\"\"\"\n",
    "    tree = lambda: defaultdict(tree)\n",
    "    root = tree()\n",
    "    for path in paths:\n",
    "        parts = Path(path).parts\n",
    "        current = root\n",
    "        for part in parts:\n",
    "            current = current[part]\n",
    "    return root\n",
    "\n",
    "\n",
    "def tree_to_markdown(tree, indent=0):\n",
    "    \"\"\"Convert nested dict to markdown bullet list with icons.\"\"\"\n",
    "    lines = []\n",
    "    for key, subtree in sorted(tree.items()):\n",
    "        if subtree:  # folder\n",
    "            lines.append(\" \" * indent + f\"- üìÅ {key}\")\n",
    "            lines.extend(tree_to_markdown(subtree, indent + 4))\n",
    "        else:  # file\n",
    "            lines.append(\" \" * indent + f\"- üìÑ {key}\")\n",
    "    return lines\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# üßæ README GENERATOR\n",
    "# ---------------------------\n",
    "\n",
    "def process_notebook(nb_path):\n",
    "    \"\"\"Helper for parallel processing: returns dict with paths and description\"\"\"\n",
    "    return {\n",
    "        \"name\": nb_path.name,\n",
    "        \"path\": nb_path,\n",
    "        \"description\": extract_description_from_notebook(nb_path),\n",
    "        \"paths\": extract_paths_from_notebook(nb_path)\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_readme(notebook_dir=\".\", output_file=\"README.md\", max_workers=4):\n",
    "    notebook_dir = Path(notebook_dir)\n",
    "    notebooks = list(notebook_dir.glob(\"*.ipynb\"))\n",
    "\n",
    "    if not notebooks:\n",
    "        print(\"No notebooks found.\")\n",
    "        return\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel notebook processing\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_nb = {executor.submit(process_notebook, nb): nb for nb in notebooks}\n",
    "\n",
    "        # Show progress bar while processing\n",
    "        for future in tqdm(as_completed(future_to_nb), total=len(future_to_nb), desc=\"Processing notebooks\"):\n",
    "            results.append(future.result())\n",
    "\n",
    "    # Sort results by notebook name\n",
    "    results = sorted(results, key=lambda x: x[\"name\"])\n",
    "\n",
    "    # Generate README lines\n",
    "    readme_lines = [\n",
    "        \"# üìò Project Notebooks Overview\",\n",
    "        \"\",\n",
    "        \"This auto-generated README provides a structured overview of all Jupyter notebooks in this project.\",\n",
    "        \"Each section lists file paths referenced in the notebook ‚Äî including glob patterns and f-strings with variables.\",\n",
    "        \"\",\n",
    "        \"---\",\n",
    "        \"\",\n",
    "    ]\n",
    "\n",
    "    for r in results:\n",
    "        rel_link = f\"[`{r['name']}`]({r['path']})\"\n",
    "        tree = build_path_tree(r[\"paths\"])\n",
    "        readme_lines += [\n",
    "            f\"## üß© {rel_link}\",\n",
    "            \"\",\n",
    "            f\"**Description:** {r['description']}\",\n",
    "            \"\",\n",
    "            \"**Referenced Paths:**\",\n",
    "        ]\n",
    "\n",
    "        if r[\"paths\"]:\n",
    "            readme_lines += tree_to_markdown(tree, indent=2)\n",
    "        else:\n",
    "            readme_lines.append(\"  - *(No file paths found)*\")\n",
    "\n",
    "        readme_lines += [\"\", \"---\", \"\"]\n",
    "\n",
    "    readme_lines += [\n",
    "        \"_This README was generated automatically ‚Äî do not edit manually unless necessary._\",\n",
    "        \"\",\n",
    "        \"Generated by `generate_notebook_readme.py` ü™Ñ\",\n",
    "    ]\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(readme_lines))\n",
    "\n",
    "    print(f\"‚úÖ README generated successfully at: {output_file}\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# üöÄ RUN SCRIPT\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Adjust max_workers based on your CPU cores\n",
    "    generate_readme(notebook_dir=\".\", max_workers=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
